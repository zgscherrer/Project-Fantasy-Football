{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Fantasy Football Data\n",
    "Need to scrape the following data:\n",
    "- Weekly Player PPR Projections: ESPN, CBS, Fantasy Football Today, Fantasy Sharks\n",
    "- Previous Week Player Actual PPR Results\n",
    "- Weekly Fanduel Player Salary (can manually download csv from a Thurs-Sun contest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "# from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to initiliaze selenium web scraper\n",
    "def instantiate_selenium_driver():\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--window-size=1420,1080')\n",
    "    #chrome_options.add_argument('--headless')\n",
    "    chrome_options.add_argument('--disable-gpu')\n",
    "    driver = webdriver.Chrome('..\\plugins\\chromedriver.exe', \n",
    "        chrome_options=chrome_options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to save dataframes to pickle archive\n",
    "#file name: don't include csv in file name, function will also add a timestamp to the archive\n",
    "#directory name don't include final backslash\n",
    "def save_to_pickle(df, directory_name, file_name):\n",
    "    lt = time.localtime()\n",
    "    full_file_name = f\"{file_name}_{lt.tm_year}-{lt.tm_mon}-{lt.tm_mday}-{lt.tm_hour}-{lt.tm_min}.pkl\"\n",
    "    path = f\"{directory_name}/{full_file_name}\"\n",
    "    df.to_pickle(path)\n",
    "    print(f\"Pickle saved to: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove name suffixes of II III IV or Jr. or Sr. or random * from names to easier match other databases\n",
    "#also remove periods from first name T.J. make TJ (just remove periods from whole name in function)\n",
    "def remove_suffixes_periods(name):\n",
    "    #remove periods and any asterisks\n",
    "    name = name.replace(\".\", \"\")\n",
    "    name = name.replace(\"*\", \"\")\n",
    "    \n",
    "    #remove any suffixes by splitting the name on spaces and then rebuilding the name with only the first two of the list (being first/last name)\n",
    "    name_split = name.split(\" \")\n",
    "    name_final = \" \".join(name_split[0:2]) #rebuild\n",
    "    \n",
    "#     #old suffix removal process (created some errors for someone with Last Name starting with V)\n",
    "#     for suffix in [\" III\", \" II\", \" IV\", \" V\", \" Jr.\", \" Sr.\"]:\n",
    "#         name = name.replace(suffix, \"\")\n",
    "\n",
    "    return name_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Weekly Player Actual Fantasy PPR Points\n",
    "Get from ESPN's Scoring Leaders table\n",
    "\n",
    "http://games.espn.com/ffl/leaders?&scoringPeriodId=1&seasonId=2018&slotCategoryId=0&leagueID=0\n",
    "- scoringPeriodId = week of the season\n",
    "- seasonId = year\n",
    "- slotCategoryId = position, where 'QB':0, 'RB':2, 'WR':4, 'TE':6, 'K':17, 'D/ST':16\n",
    "- leagueID = scoring type, PPR Standard is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SCRAPE ESPN SCORING LEADERS TABLE FOR ACTUAL FANTASY PPR POINTS##\n",
    "\n",
    "#input needs to be year as four digit number and week as number \n",
    "#returns dataframe of scraped data\n",
    "def scrape_actual_PPR_player_points_ESPN(week, year):\n",
    "    #instantiate the driver\n",
    "    driver = instantiate_selenium_driver()\n",
    "    \n",
    "    #initialize dataframe for all data\n",
    "    player_actual_ppr = pd.DataFrame()\n",
    "    \n",
    "    #url that returns info has different code for each position\n",
    "    position_ids = {'QB':0, 'RB':2, 'WR':4, 'TE':6, 'K':17, 'D/ST':16}\n",
    "\n",
    "    #cycle through each position webpage to create comprehensive dataframe\n",
    "    for pos, pos_id in position_ids.items():\n",
    "        #note leagueID=0 is for PPR standard scoring\n",
    "        url_start_pos = f\"http://games.espn.com/ffl/leaders?&scoringPeriodId={week}&seasonId={year}&slotCategoryId={pos_id}&leagueID=0\"\n",
    "        driver.get(url_start_pos)\n",
    "        \n",
    "        #each page only gets 50 results, so cycle through next button until next button no longer exists\n",
    "        while True:\n",
    "            #read in the table from ESPN, by using the class, and use the 1st row index for column header\n",
    "            player_actual_ppr_table_page = pd.read_html(driver.page_source,\n",
    "                                               attrs={'class': 'playerTableTable'}, #return only the table of this class, which has the player data\n",
    "                                               header=[1])[0] #returns table in a list, so get zeroth table\n",
    "\n",
    "            #easier to just assign the player position rather than try to scrape it out\n",
    "            player_actual_ppr_table_page['POS'] = pos\n",
    "\n",
    "            #replace any placeholder string -- or --/-- with None type to not confuse calculations later\n",
    "            player_actual_ppr_table_page.replace({'--': None, '--/--': None}, inplace=True)\n",
    "            \n",
    "\n",
    "#if want to extract more detailed data from this, can do added reformatting, etc., but not doing that for our purposes\n",
    "#             #rename D/ST columns so don't get misassigned to wrong columns\n",
    "#             if pos == 'D/ST':\n",
    "#                 player_actual_ppr_table_page.rename(columns={'SCK':'D/ST_Sack', \n",
    "#                                                      'FR':'D/ST_FR', 'INT':'D/ST_INT',\n",
    "#                                                      'TD':'D/ST_TD', 'BLK':'D/ST_BLK', 'PA':'D/ST_PA'},\n",
    "#                                                     inplace=True)\n",
    "            \n",
    "#             #rename/recalculate Kicker columns so don't get misassigned to wrong columns\n",
    "#             elif pos == 'K':\n",
    "#                 player_actual_ppr_table_page.rename(columns={'1-39':'KICK_FG_1-39', '40-49':'KICK_FG_40-49',\n",
    "#                                                      '50+':'KICK_FG_50+', 'TOT':'KICK_FG',\n",
    "#                                                      'XP':'KICK_XP'},\n",
    "#                                                     inplace=True)\n",
    "                \n",
    "#                 #if wanted to use all the kicker data could fix this code snipit - erroring out because can't split None types\n",
    "#                 #just want made FG's for each bucket and overall FGAtt and XPAtt\n",
    "#                 player_actual_ppr_table_page['KICK_FGAtt'] = player_actual_ppr_table_page['KICK_FG'].map(\n",
    "#                                                             lambda x: x.split(\"/\")[-1]).astype('float64')\n",
    "#                 player_actual_ppr_table_page['KICK_XPAtt'] = player_actual_ppr_table_page['KICK_XP'].map(\n",
    "#                                                             lambda x: x.split(\"/\")[-1]).astype('float64')\n",
    "#                 player_actual_ppr_table_page['KICK_FG_1-39'] = player_actual_ppr_table_page['KICK_FG_1-39'].map(\n",
    "#                                                             lambda x: x.split(\"/\")[0]).astype('float64')\n",
    "#                 player_actual_ppr_table_page['KICK_FG_40-49'] = player_actual_ppr_table_page['KICK_FG_40-49'].map(\n",
    "#                                                             lambda x: x.split(\"/\")[0]).astype('float64')\n",
    "#                 player_actual_ppr_table_page['KICK_FG_50+'] = player_actual_ppr_table_page['KICK_FG_50+'].map(\n",
    "#                                                             lambda x: x.split(\"/\")[0]).astype('float64')\n",
    "#                 player_actual_ppr_table_page['KICK_FG'] = player_actual_ppr_table_page['KICK_FG'].map(\n",
    "#                                                             lambda x: x.split(\"/\")[0]).astype('float64')\n",
    "#                 player_actual_ppr_table_page['KICK_XP'] = player_actual_ppr_table_page['KICK_XP'].map(\n",
    "#                                                             lambda x: x.split(\"/\")[0]).astype('float64')\n",
    "#                 player_actual_ppr_table_page['KICK_FG%'] = player_actual_ppr_table_page['KICK_FG'] / espn_proj_table_page['KICK_FGAtt']\n",
    "                           \n",
    "            \n",
    "            #add page data to overall dataframe\n",
    "            player_actual_ppr = pd.concat([player_actual_ppr, player_actual_ppr_table_page],\n",
    "                                         ignore_index=True,\n",
    "                                         sort=False)\n",
    "\n",
    "            #click to next page to get next 40 results, but check that it exists\n",
    "            try:\n",
    "                next_button = driver.find_element_by_partial_link_text('NEXT')\n",
    "                next_button.click()\n",
    "            except EC.NoSuchElementException:\n",
    "                break\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "    #drop any completely blank columns\n",
    "    player_actual_ppr.dropna(axis='columns', how='all', inplace=True)\n",
    "    \n",
    "    #add columns that give week/season\n",
    "    player_actual_ppr['WEEK'] = week\n",
    "    player_actual_ppr['SEASON'] = year\n",
    "    \n",
    "    return player_actual_ppr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###FORMAT/EXTRACT ACTUAL PLAYER PPR DATA###\n",
    "#(you could make this more complex if want to extract some of the subdata)\n",
    "\n",
    "def format_extract_PPR_player_points_ESPN(df_scraped_ppr_espn):\n",
    "    #split out player, team, position based on ESPN's formatting\n",
    "    def split_player_team_pos_espn(play_team_pos):\n",
    "        #incoming string for players: 'Todd Gurley II, LAR RB' or 'Drew Brees, NO\\xa0QB'\n",
    "        #incoming string for players with special designations: 'Aaron Rodgers, GB\\xa0QB Q'\n",
    "        #incoming string for D/ST: 'Jaguars D/ST\\xa0D/ST'\n",
    "\n",
    "        #operations if D/ST\n",
    "        if \"D/ST\" in play_team_pos:\n",
    "            player = play_team_pos.split(' D/ST\\xa0')[0]\n",
    "            team = player.split()[0]\n",
    "\n",
    "        #operations for regular players\n",
    "        else:\n",
    "            player = play_team_pos.split(',')[0]\n",
    "            team_pos = play_team_pos.split(',')[1]\n",
    "            team = team_pos.split()[0]\n",
    "\n",
    "        return player, team\n",
    "\n",
    "    \n",
    "    df_scraped_ppr_espn[['PLAYER', 'TEAM']] = df_scraped_ppr_espn.apply(\n",
    "                                               lambda x: split_player_team_pos_espn(x['PLAYER, TEAM POS']),\n",
    "                                               axis='columns',\n",
    "                                               result_type='expand')\n",
    "\n",
    "    \n",
    "    #need to remove name suffixes so can match players easier to other data - see function defined above\n",
    "    df_scraped_ppr_espn['PLAYER'] = df_scraped_ppr_espn['PLAYER'].map(remove_suffixes_periods)\n",
    "\n",
    "    #convert PTS to float type (sometimes zeros have been stored as strings)\n",
    "    df_scraped_ppr_espn['PTS'] = df_scraped_ppr_espn['PTS'].astype('float64')\n",
    "    \n",
    "    #for this function only extract 'PLAYER', 'POS', 'TEAM', 'PTS'\n",
    "    df_scraped_ppr_espn = df_scraped_ppr_espn[['PLAYER', 'POS', 'TEAM', 'PTS', 'WEEK']].sort_values('PTS', ascending=False)\n",
    "                                               \n",
    "\n",
    "    return df_scraped_ppr_espn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle saved to: pickle_archive/Week1_Player_Actual_PPR_messy_scrape_2018-9-15-22-5.pkl\n",
      "Pickle saved to: pickle_archive/Week1_Player_Actual_PPR_2018-9-15-22-5.pkl\n",
      "(1007, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>POS</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>FPTS_PPR_ACTUAL</th>\n",
       "      <th>WEEK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Alvin Kamara</td>\n",
       "      <td>RB</td>\n",
       "      <td>NO</td>\n",
       "      <td>43.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ryan Fitzpatrick</td>\n",
       "      <td>QB</td>\n",
       "      <td>TB</td>\n",
       "      <td>42.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Tyreek Hill</td>\n",
       "      <td>WR</td>\n",
       "      <td>KC</td>\n",
       "      <td>42.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>Michael Thomas</td>\n",
       "      <td>WR</td>\n",
       "      <td>NO</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>James Conner</td>\n",
       "      <td>RB</td>\n",
       "      <td>Pit</td>\n",
       "      <td>34.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               PLAYER POS TEAM  FPTS_PPR_ACTUAL  WEEK\n",
       "120      Alvin Kamara  RB   NO             43.1     1\n",
       "0    Ryan Fitzpatrick  QB   TB             42.3     1\n",
       "387       Tyreek Hill  WR   KC             42.3     1\n",
       "388    Michael Thomas  WR   NO             38.0     1\n",
       "121      James Conner  RB  Pit             34.2     1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CALL SCRAPE AND FORMATTING OF ACTUAL PPR WEEK 1- AND SAVE TO PICKLES FOR LATER USE\n",
    "\n",
    "#scrape data and save the messy full dataframe\n",
    "df_wk1_player_actual_ppr_scrape = scrape_actual_PPR_player_points_ESPN(1, 2018)\n",
    "save_to_pickle(df_wk1_player_actual_ppr_scrape, 'pickle_archive', 'Week1_Player_Actual_PPR_messy_scrape')\n",
    "\n",
    "#format data to extract just player pts/playr/pos/team/weel and save the data\n",
    "df_wk1_player_actual_ppr = format_extract_PPR_player_points_ESPN(df_wk1_player_actual_ppr_scrape)\n",
    "#rename PTS column to something more descriptive \n",
    "df_wk1_player_actual_ppr.rename(columns={'PTS':'FPTS_PPR_ACTUAL'}, inplace=True) \n",
    "save_to_pickle(df_wk1_player_actual_ppr, 'pickle_archive', 'Week1_Player_Actual_PPR')\n",
    "print(df_wk1_player_actual_ppr.shape)\n",
    "df_wk1_player_actual_ppr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ESPN Player Fantasy Points Projections for Week \n",
    "Get from ESPN's Projections Table\n",
    "\n",
    "http://games.espn.com/ffl/tools/projections?&scoringPeriodId=1&seasonId=2018&slotCategoryId=0&leagueID=0\n",
    "- scoringPeriodId = week of the season\n",
    "- seasonId = year\n",
    "- slotCategoryId = position, where 'QB':0, 'RB':2, 'WR':4, 'TE':6, 'K':17, 'D/ST':16\n",
    "- leagueID = scoring type, PPR Standard is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SCRAPE ESPN PROJECTIONS TABLE FOR PROJECTED FANTASY PPR POINTS##\n",
    "\n",
    "#input needs to be year as four digit number and week as number \n",
    "#returns dataframe of scraped data\n",
    "def scrape_weekly_player_projections_ESPN(week, year):\n",
    "    #instantiate the driver on the ESPN projections page\n",
    "    driver = instantiate_selenium_driver()\n",
    "    \n",
    "    #initialize dataframe for all data\n",
    "    proj_ppr_espn = pd.DataFrame()\n",
    "    \n",
    "    #url that returns info has different code for each position\n",
    "    position_ids = {'QB':0, 'RB':2, 'WR':4, 'TE':6, 'K':17, 'D/ST':16}\n",
    "\n",
    "    #cycle through each position webpage to create comprehensive dataframe\n",
    "    for pos, pos_id in position_ids.items():\n",
    "        #note leagueID=0 is for PPR standard scoring\n",
    "        url_start_pos = f\"http://games.espn.com/ffl/tools/projections?&scoringPeriodId={week}&seasonId={year}&slotCategoryId={pos_id}&leagueID=0\"       \n",
    "        driver.get(url_start_pos)\n",
    "        \n",
    "        #each page only gets 50 results, so cycle through next button until next button no longer exists\n",
    "        while True:\n",
    "            #read in the table from ESPN, by using the class, and use the 1st row index for column header\n",
    "            proj_ppr_espn_table_page = pd.read_html(driver.page_source,\n",
    "                                               attrs={'class': 'playerTableTable'}, #return only the table of this class, which has the player data\n",
    "                                               header=[1])[0] #returns table in a list, so get zeroth table\n",
    "\n",
    "            #easier to just assign the player position rather than try to scrape it out\n",
    "            proj_ppr_espn_table_page['POS'] = pos\n",
    "\n",
    "            #replace any placeholder string -- or --/-- with None type to not confuse calculations later\n",
    "            proj_ppr_espn_table_page.replace({'--': None, '--/--': None}, inplace=True)\n",
    "\n",
    "\n",
    "#if want to extract more detailed data from this, can do added reformatting, etc., but not doing that for our purposes\n",
    "#             #rename D/ST columns so don't get misassigned to wrong columns\n",
    "#             if pos == 'D/ST':\n",
    "#                 proj_ppr_espn_table_page.rename(columns={'SCK':'D/ST_Sack', \n",
    "#                                                      'FR':'D/ST_FR', 'INT':'D/ST_INT',\n",
    "#                                                      'TD':'D/ST_TD', 'BLK':'D/ST_BLK', 'PA':'D/ST_PA'},\n",
    "#                                                     inplace=True)\n",
    "            \n",
    "#             #rename/recalculate Kicker columns so don't get misassigned to wrong columns\n",
    "#             elif pos == 'K':\n",
    "#                 proj_ppr_espn_table_page.rename(columns={'1-39':'KICK_FG_1-39', '40-49':'KICK_FG_40-49',\n",
    "#                                                      '50+':'KICK_FG_50+', 'TOT':'KICK_FG',\n",
    "#                                                      'XP':'KICK_XP'},\n",
    "#                                                     inplace=True)\n",
    "                \n",
    "#                 #if wanted to use all the kicker data could fix this code snipit - erroring out because can't split None types\n",
    "#                 #just want made FG's for each bucket and overall FGAtt and XPAtt\n",
    "#                 proj_ppr_espn_table_page['KICK_FGAtt'] = proj_ppr_espn_table_page['KICK_FG'].map(\n",
    "#                                                             lambda x: x.split(\"/\")[-1]).astype('float64')\n",
    "#                 proj_ppr_espn_table_page['KICK_XPAtt'] = proj_ppr_espn_table_page['KICK_XP'].map(\n",
    "#                                                             lambda x: x.split(\"/\")[-1]).astype('float64')\n",
    "#                 proj_ppr_espn_table_page['KICK_FG_1-39'] = proj_ppr_espn_table_page['KICK_FG_1-39'].map(\n",
    "#                                                             lambda x: x.split(\"/\")[0]).astype('float64')\n",
    "#                 proj_ppr_espn_table_page['KICK_FG_40-49'] = proj_ppr_espn_table_page['KICK_FG_40-49'].map(\n",
    "#                                                             lambda x: x.split(\"/\")[0]).astype('float64')\n",
    "#                 proj_ppr_espn_table_page['KICK_FG_50+'] = proj_ppr_espn_table_page['KICK_FG_50+'].map(\n",
    "#                                                             lambda x: x.split(\"/\")[0]).astype('float64')\n",
    "#                 proj_ppr_espn_table_page['KICK_FG'] = proj_ppr_espn_table_page['KICK_FG'].map(\n",
    "#                                                             lambda x: x.split(\"/\")[0]).astype('float64')\n",
    "#                 proj_ppr_espn_table_page['KICK_XP'] = proj_ppr_espn_table_page['KICK_XP'].map(\n",
    "#                                                             lambda x: x.split(\"/\")[0]).astype('float64')\n",
    "#                 proj_ppr_espn_table_page['KICK_FG%'] = proj_ppr_espn_table_page['KICK_FG'] / espn_proj_table_page['KICK_FGAtt']\n",
    "                           \n",
    "            \n",
    "            #add page data to overall dataframe\n",
    "            proj_ppr_espn = pd.concat([proj_ppr_espn, proj_ppr_espn_table_page],\n",
    "                                         ignore_index=True,\n",
    "                                         sort=False)\n",
    "\n",
    "            #click to next page to get next 40 results, but check that it exists\n",
    "            try:\n",
    "                next_button = driver.find_element_by_partial_link_text('NEXT')\n",
    "                next_button.click()\n",
    "            except EC.NoSuchElementException:\n",
    "                break\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "    #drop any completely blank columns\n",
    "    proj_ppr_espn.dropna(axis='columns', how='all', inplace=True)\n",
    "    \n",
    "    #add columns that give week/season\n",
    "    proj_ppr_espn['WEEK'] = week\n",
    "    proj_ppr_espn['SEASON'] = year\n",
    "    \n",
    "    return proj_ppr_espn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formatting/extracting function is same for ESPN Actual/PPR Projections, so don't need new function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle saved to: pickle_archive/Week1_PPR_Projections_ESPN_messy_scrape_2018-9-15-22-7.pkl\n",
      "Pickle saved to: pickle_archive/Week1_PPR_Projections_ESPN_2018-9-15-22-7.pkl\n",
      "(1007, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>POS</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>FPTS_PPR_ESPN</th>\n",
       "      <th>WEEK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Alvin Kamara</td>\n",
       "      <td>RB</td>\n",
       "      <td>NO</td>\n",
       "      <td>22.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>David Johnson</td>\n",
       "      <td>RB</td>\n",
       "      <td>Ari</td>\n",
       "      <td>21.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Todd Gurley</td>\n",
       "      <td>RB</td>\n",
       "      <td>LAR</td>\n",
       "      <td>21.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Antonio Brown</td>\n",
       "      <td>WR</td>\n",
       "      <td>Pit</td>\n",
       "      <td>19.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tom Brady</td>\n",
       "      <td>QB</td>\n",
       "      <td>NE</td>\n",
       "      <td>19.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PLAYER POS TEAM  FPTS_PPR_ESPN  WEEK\n",
       "120   Alvin Kamara  RB   NO           22.2     1\n",
       "121  David Johnson  RB  Ari           21.3     1\n",
       "122    Todd Gurley  RB  LAR           21.2     1\n",
       "387  Antonio Brown  WR  Pit           19.5     1\n",
       "0        Tom Brady  QB   NE           19.4     1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WEEK 1 PROJECTIONS\n",
    "#CALL SCRAPE AND FORMATTING OF ESPN WEEKLY PROJECTIONS - AND SAVE TO PICKLES FOR LATER USE\n",
    "\n",
    "#scrape data and save the messy full dataframe\n",
    "df_wk1_ppr_proj_espn_scrape = scrape_weekly_player_projections_ESPN(1, 2018)\n",
    "save_to_pickle(df_wk1_ppr_proj_espn_scrape, 'pickle_archive', 'Week1_PPR_Projections_ESPN_messy_scrape')\n",
    "\n",
    "#format data to extract just player pts/playr/pos/team/week and save the data\n",
    "df_wk1_ppr_proj_espn = format_extract_PPR_player_points_ESPN(df_wk1_ppr_proj_espn_scrape)\n",
    "#rename PTS column to something more descriptive \n",
    "df_wk1_ppr_proj_espn.rename(columns={'PTS':'FPTS_PPR_ESPN'}, inplace=True) \n",
    "save_to_pickle(df_wk1_ppr_proj_espn, 'pickle_archive', 'Week1_PPR_Projections_ESPN')\n",
    "print(df_wk1_ppr_proj_espn.shape)\n",
    "df_wk1_ppr_proj_espn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle saved to: pickle_archive/Week2_PPR_Projections_ESPN_messy_scrape_2018-9-15-22-9.pkl\n",
      "Pickle saved to: pickle_archive/Week2_PPR_Projections_ESPN_2018-9-15-22-9.pkl\n",
      "(1007, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>POS</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>FPTS_PPR_ESPN</th>\n",
       "      <th>WEEK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Alvin Kamara</td>\n",
       "      <td>RB</td>\n",
       "      <td>NO</td>\n",
       "      <td>22.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Todd Gurley</td>\n",
       "      <td>RB</td>\n",
       "      <td>LAR</td>\n",
       "      <td>22.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Ezekiel Elliott</td>\n",
       "      <td>RB</td>\n",
       "      <td>Dal</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Antonio Brown</td>\n",
       "      <td>WR</td>\n",
       "      <td>Pit</td>\n",
       "      <td>20.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>Michael Thomas</td>\n",
       "      <td>WR</td>\n",
       "      <td>NO</td>\n",
       "      <td>19.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PLAYER POS TEAM  FPTS_PPR_ESPN  WEEK\n",
       "120     Alvin Kamara  RB   NO           22.8     2\n",
       "121      Todd Gurley  RB  LAR           22.4     2\n",
       "122  Ezekiel Elliott  RB  Dal           21.0     2\n",
       "387    Antonio Brown  WR  Pit           20.6     2\n",
       "388   Michael Thomas  WR   NO           19.3     2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WEEK 2 PROJECTIONS\n",
    "#CALL SCRAPE AND FORMATTING OF ESPN WEEKLY PROJECTIONS - AND SAVE TO PICKLES FOR LATER USE\n",
    "\n",
    "#scrape data and save the messy full dataframe\n",
    "df_wk2_ppr_proj_espn_scrape = scrape_weekly_player_projections_ESPN(2, 2018)\n",
    "save_to_pickle(df_wk2_ppr_proj_espn_scrape, 'pickle_archive', 'Week2_PPR_Projections_ESPN_messy_scrape')\n",
    "\n",
    "#format data to extract just player pts/playr/pos/team/week and save the data\n",
    "df_wk2_ppr_proj_espn = format_extract_PPR_player_points_ESPN(df_wk2_ppr_proj_espn_scrape)\n",
    "#rename PTS column to something more descriptive \n",
    "df_wk2_ppr_proj_espn.rename(columns={'PTS':'FPTS_PPR_ESPN'}, inplace=True) \n",
    "save_to_pickle(df_wk2_ppr_proj_espn, 'pickle_archive', 'Week2_PPR_Projections_ESPN')\n",
    "print(df_wk2_ppr_proj_espn.shape)\n",
    "df_wk2_ppr_proj_espn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CBS Player Fantasy Points Projections for Week \n",
    "Get from CBS's Projections Table\n",
    "\n",
    "https://www.cbssports.com/fantasy/football/stats/sortable/points/QB/ppr/projections/2018/2?&print_rows=9999\n",
    "- QB is where position goes\n",
    "- 2018 is where season goes\n",
    "- 2 is where week goes\n",
    "- print_rows = 9999 gives all results in one table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SCRAPE CBS PROJECTIONS TABLE FOR PROJECTED FANTASY PPR POINTS##\n",
    "\n",
    "#input needs to be year as four digit number and week as number \n",
    "#returns dataframe of scraped data\n",
    "def scrape_weekly_player_projections_CBS(week, year):\n",
    "    ###GET PROJECTIONS FROM CBS###\n",
    "    #CBS has separate tables for each position, so need to cycle through them\n",
    "    #but url can return all list so don't need to go page by page\n",
    "    proj_ppr_cbs = pd.DataFrame()\n",
    "    \n",
    "    positions = ['QB', 'RB', 'WR', 'TE', 'K', 'DST']\n",
    "    header_row_index = {'QB':2, 'RB':2, 'WR':2, 'TE':2, 'K':1, 'DST':1}\n",
    "       \n",
    "    for position in positions:\n",
    "        #url just needs to change position\n",
    "        url = f\"https://www.cbssports.com/fantasy/football/stats/sortable/points/{position}/ppr/projections/{year}/{week}?&print_rows=9999\"\n",
    "    \n",
    "        #read in the table from CBS by class, and use the 2nd row index for column header\n",
    "        proj_ppr_cbs_pos = pd.read_html(url, \n",
    "                                  attrs={'class': 'data'}, #return only the table of this class, which has the player data\n",
    "                                  header=[header_row_index[position]])[0] #returns table in a list, so get table\n",
    "        proj_ppr_cbs_pos['POS'] = position\n",
    "        \n",
    "        #add the table to the overall df\n",
    "        proj_ppr_cbs = pd.concat([proj_ppr_cbs, proj_ppr_cbs_pos], \n",
    "                             ignore_index=True, \n",
    "                             sort=False)\n",
    "\n",
    "    #some tables include the page selector as the bottom row of the table,\n",
    "    #so need to find the index values of those rows and then drop them from the table\n",
    "    index_pages_rows = list(proj_ppr_cbs[proj_ppr_cbs['Player'].str.contains('Pages')].index)\n",
    "    proj_ppr_cbs.drop(index_pages_rows, axis='index', inplace=True)\n",
    "    \n",
    "    #add columns that give week/season\n",
    "    proj_ppr_cbs['WEEK'] = week\n",
    "    proj_ppr_cbs['SEASON'] = year\n",
    "    \n",
    "    return proj_ppr_cbs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###FORMAT/EXTRACT ACTUAL PLAYER PPR DATA###\n",
    "#(you could make this more complex if want to extract some of the subdata)\n",
    "\n",
    "def format_extract_PPR_player_points_CBS(df_scraped_ppr_cbs):\n",
    "# #could include this extra data if you want to extract it\n",
    "#     #calculate completion percentage\n",
    "#     df_cbs_proj['COMPLETION_PERCENTAGE'] = df_cbs_proj.CMP/df_cbs_proj.ATT\n",
    "\n",
    "\n",
    "#     #rename some of columns so don't lose meaning\n",
    "#     df_cbs_proj.rename(columns={'ATT':'PASS_ATT', 'CMP':'PASS_COMP', 'COMPLETION_PERCENTAGE': 'PASS_COMP_PCT',\n",
    "#                                        'YD': 'PASS_YD', 'TD':'PASS_TD', 'INT':'PASS_INT', 'RATE':'PASS_RATE', \n",
    "#                                        'ATT.1': 'RUSH_ATT', 'YD.1': 'RUSH_YD', 'AVG': 'RUSH_AVG', 'TD.1':'RUSH_TD',\n",
    "#                                        'TARGT': 'RECV_TARGT', 'RECPT': 'RECV_RECPT', 'YD.2':'RECV_YD', 'AVG.1':'RECV_AVG', 'TD.2':'RECV_TD',\n",
    "#                                        'FPTS':'PTS',\n",
    "#                                        'FG':'KICK_FG', 'FGA': 'KICK_FGAtt', 'XP':'KICK_XP', 'XPAtt':'KICK_XPAtt', \n",
    "#                                        'Int':'D/ST_INT', 'Sty':'D/ST_Sty', 'Sack':'D/ST_Sack', 'TK':'D/ST_TK',\n",
    "#                                        'DFR':'D/ST_FR', 'FF':'D/ST_FF', 'DTD':'D/ST_TD',\n",
    "#                                        'Pa':'D/ST_PtsAll', 'PaNetA':'D/ST_PaYdA', 'RuYdA':'D/ST_RuYdA', 'TyDa':'D/ST_ToYdA'},\n",
    "#                                 inplace=True)\n",
    "\n",
    "\n",
    "#     #calculate passing, rushing, total yards/game\n",
    "#     df_cbs_proj['D/ST_PaYd/G'] = df_cbs_proj['D/ST_PaYdA']/16\n",
    "#     df_cbs_proj['D/ST_RuYd/G'] = df_cbs_proj['D/ST_RuYdA']/16\n",
    "#     df_cbs_proj['D/ST_ToYd/G'] = df_cbs_proj['D/ST_ToYdA']/16\n",
    "\n",
    "\n",
    "    #rename FPTS to PTS\n",
    "    df_scraped_ppr_cbs.rename(columns={'FPTS':'FPTS_PPR_CBS'}, inplace=True) \n",
    "                              \n",
    "\n",
    "    #split out player, team\n",
    "    def split_player_team(play_team):\n",
    "        #incoming string for players: 'Todd Gurley, LAR'\n",
    "        #incoming string for DST: 'Jaguars, JAC'\n",
    "\n",
    "        #operations if D/ST (can tell if there is only two items in a list separated by a space, instead of three)\n",
    "        if len(play_team.split()) == 2:\n",
    "            player = play_team.split(',')[0] #+ ' D/ST'\n",
    "            team = play_team.split(',')[1]\n",
    "\n",
    "        #operations for regular players\n",
    "        else:\n",
    "            player = play_team.split(',')[0]\n",
    "            team = play_team.split(',')[1]\n",
    "        \n",
    "        #remove any possible name suffixes to merge with other data better\n",
    "        player = remove_suffixes_periods(player)\n",
    "        \n",
    "        return player, team\n",
    "\n",
    "    \n",
    "    df_scraped_ppr_cbs[['PLAYER', 'TEAM']] = df_scraped_ppr_cbs.apply(\n",
    "                                                    lambda x: split_player_team(x['Player']),\n",
    "                                                    axis='columns',\n",
    "                                                    result_type='expand')\n",
    "\n",
    "    \n",
    "    #for this function only extract 'PLAYER', 'POS', 'TEAM', 'PTS'\n",
    "    df_scraped_ppr_cbs = df_scraped_ppr_cbs[['PLAYER', 'POS', 'TEAM', 'FPTS_PPR_CBS', 'WEEK']].sort_values('FPTS_PPR_CBS', ascending=False)\n",
    "\n",
    "\n",
    "    return df_scraped_ppr_cbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle saved to: pickle_archive/Week1_PPR_Projections_CBS_messy_scrape_2018-9-15-22-9.pkl\n",
      "Pickle saved to: pickle_archive/Week1_PPR_Projections_CBS_2018-9-15-22-9.pkl\n",
      "(793, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>POS</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>FPTS_PPR_CBS</th>\n",
       "      <th>WEEK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drew Brees</td>\n",
       "      <td>QB</td>\n",
       "      <td>NO</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Todd Gurley</td>\n",
       "      <td>RB</td>\n",
       "      <td>LAR</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deshaun Watson</td>\n",
       "      <td>QB</td>\n",
       "      <td>HOU</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Antonio Brown</td>\n",
       "      <td>WR</td>\n",
       "      <td>PIT</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>DeAndre Hopkins</td>\n",
       "      <td>WR</td>\n",
       "      <td>HOU</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PLAYER POS  TEAM  FPTS_PPR_CBS  WEEK\n",
       "0         Drew Brees  QB    NO          23.0     1\n",
       "109      Todd Gurley  RB   LAR          23.0     1\n",
       "1     Deshaun Watson  QB   HOU          23.0     1\n",
       "306    Antonio Brown  WR   PIT          22.0     1\n",
       "307  DeAndre Hopkins  WR   HOU          22.0     1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WEEK 1 PROJECTIONS\n",
    "#CALL SCRAPE AND FORMATTING OF CBS WEEKLY PROJECTIONS - AND SAVE TO PICKLES FOR LATER USE\n",
    "\n",
    "#scrape data and save the messy full dataframe\n",
    "df_wk1_ppr_proj_cbs_scrape = scrape_weekly_player_projections_CBS(1, 2018)\n",
    "save_to_pickle(df_wk1_ppr_proj_cbs_scrape, 'pickle_archive', 'Week1_PPR_Projections_CBS_messy_scrape')\n",
    "\n",
    "#format data to extract just player pts/playr/pos/team and save the data\n",
    "df_wk1_ppr_proj_cbs = format_extract_PPR_player_points_CBS(df_wk1_ppr_proj_cbs_scrape)\n",
    "save_to_pickle(df_wk1_ppr_proj_cbs, 'pickle_archive', 'Week1_PPR_Projections_CBS')\n",
    "print(df_wk1_ppr_proj_cbs.shape)\n",
    "df_wk1_ppr_proj_cbs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle saved to: pickle_archive/Week2_PPR_Projections_CBS_messy_scrape_2018-9-15-22-10.pkl\n",
      "Pickle saved to: pickle_archive/Week2_PPR_Projections_CBS_2018-9-15-22-10.pkl\n",
      "(816, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>POS</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>FPTS_PPR_CBS</th>\n",
       "      <th>WEEK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>Antonio Brown</td>\n",
       "      <td>WR</td>\n",
       "      <td>PIT</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drew Brees</td>\n",
       "      <td>QB</td>\n",
       "      <td>NO</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Alvin Kamara</td>\n",
       "      <td>RB</td>\n",
       "      <td>NO</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patrick Mahomes</td>\n",
       "      <td>QB</td>\n",
       "      <td>KC</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Todd Gurley</td>\n",
       "      <td>RB</td>\n",
       "      <td>LAR</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PLAYER POS  TEAM  FPTS_PPR_CBS  WEEK\n",
       "319    Antonio Brown  WR   PIT          26.0     2\n",
       "0         Drew Brees  QB    NO          22.0     2\n",
       "114     Alvin Kamara  RB    NO          21.0     2\n",
       "1    Patrick Mahomes  QB    KC          21.0     2\n",
       "115      Todd Gurley  RB   LAR          21.0     2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WEEK 2 PROJECTIONS\n",
    "#CALL SCRAPE AND FORMATTING OF CBS WEEKLY PROJECTIONS - AND SAVE TO PICKLES FOR LATER USE\n",
    "\n",
    "#scrape data and save the messy full dataframe\n",
    "df_wk2_ppr_proj_cbs_scrape = scrape_weekly_player_projections_CBS(2, 2018)\n",
    "save_to_pickle(df_wk2_ppr_proj_cbs_scrape, 'pickle_archive', 'Week2_PPR_Projections_CBS_messy_scrape')\n",
    "\n",
    "#format data to extract just player pts/playr/pos/team/week and save the data\n",
    "df_wk2_ppr_proj_cbs = format_extract_PPR_player_points_CBS(df_wk2_ppr_proj_cbs_scrape)\n",
    "save_to_pickle(df_wk2_ppr_proj_cbs, 'pickle_archive', 'Week2_PPR_Projections_CBS')\n",
    "print(df_wk2_ppr_proj_cbs.shape)\n",
    "df_wk2_ppr_proj_cbs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Fantasy Sharks Player Points Projection for Week\n",
    "They have a json option that gets updated weekly (don't appear to store previous week projections).  The json defaults to PPR (which is lucky for us) and has an all players option.\n",
    "\n",
    "https://www.fantasysharks.com/apps/Projections/WeeklyProjections.php?pos=ALL&format=json\n",
    "It returns a list of players, each saved as a dictionary.\n",
    "\n",
    "[\n",
    "  {\n",
    "    \"Rank\": 1,\n",
    "    \"ID\": \"4925\",\n",
    "    \"Name\": \"Brees, Drew\",\n",
    "    \"Pos\": \"QB\",\n",
    "    \"Team\": \"NOS\",\n",
    "    \"Opp\": \"CLE\",\n",
    "    \"Comp\": \"27.49\",\n",
    "    \"PassYards\": \"337\",\n",
    "    \"PassTD\": 2.15,\n",
    "    \"Int\": \"0.61\",\n",
    "    \"Att\": \"1.5\",\n",
    "    \"RushYards\": \"0\",\n",
    "    \"RushTD\": 0.12,\n",
    "    \"Rec\": \"0\",\n",
    "    \"RecYards\": \"0\",\n",
    "    \"RecTD\": 0,\n",
    "    \"FantasyPoints\": 26\n",
    "  },\n",
    "  \n",
    "But the json is only for current week, can't get other week data - so instead use this url exampe:\n",
    "https://www.fantasysharks.com/apps/bert/forecasts/projections.php?Position=99&scoring=2&Segment=628&uid=4\n",
    "- Segment is the week/season id - for 2018 week 1 starts at 628 and adds 1 for each additional week\n",
    "- Position=99 is all positions\n",
    "- scoring=2 is PPR default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SCRAPE FANTASY SHARKS PROJECTIONS TABLE FOR PROJECTED FANTASY PPR POINTS##\n",
    "\n",
    "#input needs to be week as number (year isn't used, but keep same format as others)\n",
    "#returns dataframe of scraped data\n",
    "def scrape_weekly_player_projections_Sharks(week, year):\n",
    "    #fantasy sharks url - segment for 2018 week 1 starts at 628 and adds 1 for each additional week\n",
    "    segment = 627 + week\n",
    "    #Position=99 is all positions, and scoring=2 is PPR default\n",
    "    sharks_weekly_url = f\"https://www.fantasysharks.com/apps/bert/forecasts/projections.php?Position=99&scoring=2&Segment={segment}&uid=4\"\n",
    "\n",
    "    #since don't need to iterate over pages, can just use reqeuests instead of selenium scraper\n",
    "    #however with requests, need to include headers because this website was rejecting the request since it knew python was running it - need to spoof a browser header\n",
    "    #other possible headers: 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1)'}\n",
    "    #response returns html\n",
    "    response = requests.get(sharks_weekly_url, headers=headers)\n",
    "\n",
    "    #extract the table data from the html response (call response.text) and get table with player data\n",
    "    proj_ppr_sharks = pd.read_html(response.text, #response.text gives the html of the page request\n",
    "                                   attrs={'id': 'toolData'}, #return only the table of this id, which has the player data\n",
    "                                   header = 0 #header is the 0th row\n",
    "                                   )[0] #pd.read_html returns a list of tables even though only one in it, select the table\n",
    "    \n",
    "    #the webpage uses different tiers, which add extra rows to the table - get rid of those\n",
    "    #also sometimes repeats the column headers for readability as scrolling - get rid of those\n",
    "    #so need to find the index values of those bad rows and then drop them from the table\n",
    "    index_pages_rows = list(proj_ppr_sharks[proj_ppr_sharks['#'].str.contains('Tier|#')].index)\n",
    "    proj_ppr_sharks.drop(index_pages_rows, axis='index', inplace=True)\n",
    "    \n",
    "    #add columns that give week/season\n",
    "    proj_ppr_sharks['WEEK'] = week\n",
    "    proj_ppr_sharks['SEASON'] = year\n",
    "    \n",
    "    return proj_ppr_sharks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###FORMAT/EXTRACT ACTUAL PLAYER PPR DATA###\n",
    "#(you could make this more complex if want to extract some of the subdata like opposing team (OPP)\n",
    "\n",
    "def format_extract_PPR_player_points_Sharks(df_scraped_ppr_sharks):\n",
    "    #rename PTS to FPTS_PPR_SHARKS and a few others\n",
    "    df_scraped_ppr_sharks.rename(columns={'Pts':'FPTS_PPR_SHARKS',\n",
    "                                          'Player': 'PLAYER',\n",
    "                                          'Tm': 'TEAM',\n",
    "                                          'Position': 'POS'},\n",
    "                                 inplace=True) \n",
    "                              \n",
    "    #they have player name as Last Name, First Name - reorder to First Last\n",
    "    def modify_player_name(player, pos):\n",
    "        #incoming string for players: 'Johnson, David' Change to: 'David Johnson'\n",
    "        #incoming string for defense: 'Lions, Detroit' Change to: 'Lions'\n",
    "        if pos == 'D':\n",
    "            player_formatted = player.split(', ')[0]\n",
    "        else:\n",
    "            player_formatted = ' '.join(player.split(', ')[::-1])\n",
    "            player_formatted = remove_suffixes_periods(player_formatted)\n",
    "            \n",
    "        #name overrides - some spelling differences from ESPN/CBS\n",
    "        if player_formatted == 'Steven Hauschka':\n",
    "            player_formatted = 'Stephen Hauschka'\n",
    "        elif player_formatted == 'Josh Bellamy':\n",
    "            player_formatted = 'Joshua Bellamy'\n",
    "        elif player_formatted == 'Joshua Perkins':    \n",
    "            player_formatted = 'Josh Perkins'\n",
    "        \n",
    "        return player_formatted\n",
    "\n",
    "    df_scraped_ppr_sharks['PLAYER'] = df_scraped_ppr_sharks.apply(\n",
    "                                            lambda row: modify_player_name(row['PLAYER'], row['POS']),\n",
    "                                            axis='columns')\n",
    "    \n",
    "\n",
    "    \n",
    "    #convert FPTS to float type (currently stored as string)\n",
    "    df_scraped_ppr_sharks['FPTS_PPR_SHARKS'] = df_scraped_ppr_sharks['FPTS_PPR_SHARKS'].astype('float64')\n",
    "    \n",
    "    #for this function only extract 'PLAYER', 'POS', 'TEAM', 'FPTS'\n",
    "    df_scraped_ppr_sharks = df_scraped_ppr_sharks[['PLAYER', 'POS', 'TEAM', 'FPTS_PPR_SHARKS', 'WEEK']].sort_values('FPTS_PPR_SHARKS', ascending=False)\n",
    "\n",
    "\n",
    "    return df_scraped_ppr_sharks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle saved to: pickle_archive/Week1_PPR_Projections_Sharks_messy_scrape_2018-9-15-22-10.pkl\n",
      "Pickle saved to: pickle_archive/Week1_PPR_Projections_Sharks_2018-9-15-22-10.pkl\n",
      "(918, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>POS</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>FPTS_PPR_SHARKS</th>\n",
       "      <th>WEEK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tom Brady</td>\n",
       "      <td>QB</td>\n",
       "      <td>NEP</td>\n",
       "      <td>27.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>David Johnson</td>\n",
       "      <td>RB</td>\n",
       "      <td>ARZ</td>\n",
       "      <td>23.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matthew Stafford</td>\n",
       "      <td>QB</td>\n",
       "      <td>DET</td>\n",
       "      <td>23.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ben Roethlisberger</td>\n",
       "      <td>QB</td>\n",
       "      <td>PIT</td>\n",
       "      <td>22.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Russell Wilson</td>\n",
       "      <td>QB</td>\n",
       "      <td>SEA</td>\n",
       "      <td>22.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               PLAYER POS TEAM  FPTS_PPR_SHARKS  WEEK\n",
       "0           Tom Brady  QB  NEP             27.4     1\n",
       "1       David Johnson  RB  ARZ             23.6     1\n",
       "3    Matthew Stafford  QB  DET             23.2     1\n",
       "4  Ben Roethlisberger  QB  PIT             22.9     1\n",
       "6      Russell Wilson  QB  SEA             22.8     1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WEEK 1 PROJECTIONS\n",
    "#CALL SCRAPE AND FORMATTING OF FANTASY SHARKS WEEKLY PROJECTIONS - AND SAVE TO PICKLES FOR LATER USE\n",
    "\n",
    "#scrape data and save the messy full dataframe\n",
    "df_wk1_ppr_proj_sharks_scrape = scrape_weekly_player_projections_Sharks(1, 2018)\n",
    "save_to_pickle(df_wk1_ppr_proj_sharks_scrape, 'pickle_archive', 'Week1_PPR_Projections_Sharks_messy_scrape')\n",
    "\n",
    "#format data to extract just player pts/playr/pos/team/week and save the data\n",
    "df_wk1_ppr_proj_sharks = format_extract_PPR_player_points_Sharks(df_wk1_ppr_proj_sharks_scrape)\n",
    "save_to_pickle(df_wk1_ppr_proj_sharks, 'pickle_archive', 'Week1_PPR_Projections_Sharks')\n",
    "print(df_wk1_ppr_proj_sharks.shape)\n",
    "df_wk1_ppr_proj_sharks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle saved to: pickle_archive/Week2_PPR_Projections_Sharks_messy_scrape_2018-9-15-22-10.pkl\n",
      "Pickle saved to: pickle_archive/Week2_PPR_Projections_Sharks_2018-9-15-22-10.pkl\n",
      "(992, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>POS</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>FPTS_PPR_SHARKS</th>\n",
       "      <th>WEEK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drew Brees</td>\n",
       "      <td>QB</td>\n",
       "      <td>NOR</td>\n",
       "      <td>25.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alvin Kamara</td>\n",
       "      <td>RB</td>\n",
       "      <td>NOR</td>\n",
       "      <td>24.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Russell Wilson</td>\n",
       "      <td>QB</td>\n",
       "      <td>SEA</td>\n",
       "      <td>23.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Patrick Mahomes</td>\n",
       "      <td>QB</td>\n",
       "      <td>KCC</td>\n",
       "      <td>22.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alex Smith</td>\n",
       "      <td>QB</td>\n",
       "      <td>WAS</td>\n",
       "      <td>22.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PLAYER POS TEAM  FPTS_PPR_SHARKS  WEEK\n",
       "0       Drew Brees  QB  NOR             25.6     2\n",
       "1     Alvin Kamara  RB  NOR             24.1     2\n",
       "3   Russell Wilson  QB  SEA             23.1     2\n",
       "6  Patrick Mahomes  QB  KCC             22.7     2\n",
       "4       Alex Smith  QB  WAS             22.7     2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WEEK 2 PROJECTIONS\n",
    "#CALL SCRAPE AND FORMATTING OF FANTASY SHARKS WEEKLY PROJECTIONS - AND SAVE TO PICKLES FOR LATER USE\n",
    "\n",
    "#scrape data and save the messy full dataframe\n",
    "df_wk2_ppr_proj_sharks_scrape = scrape_weekly_player_projections_Sharks(2, 2018)\n",
    "save_to_pickle(df_wk2_ppr_proj_sharks_scrape, 'pickle_archive', 'Week2_PPR_Projections_Sharks_messy_scrape')\n",
    "\n",
    "#format data to extract just player pts/playr/pos/team and save the data\n",
    "df_wk2_ppr_proj_sharks = format_extract_PPR_player_points_Sharks(df_wk2_ppr_proj_sharks_scrape)\n",
    "save_to_pickle(df_wk2_ppr_proj_sharks, 'pickle_archive', 'Week2_PPR_Projections_Sharks')\n",
    "print(df_wk2_ppr_proj_sharks.shape)\n",
    "df_wk2_ppr_proj_sharks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Scout Fantasy Sports Player Fantasy Points Projections for Week \n",
    "Get from Scout Fantasy Sports Projections Table\n",
    "\n",
    "https://fftoolbox.scoutfantasysports.com/football/rankings/?pos=rb&week=2&noppr=false\n",
    "- pos is position with options of 'QB','RB','WR','TE', 'K', 'DEF'\n",
    "- week is week of year\n",
    "- noppr is set to false when you want the ppr projections\n",
    "- it also returns one long table (no pagination required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SCRAPE Scout PROJECTIONS TABLE FOR PROJECTED FANTASY PPR POINTS##\n",
    "\n",
    "#input needs to be year as four digit number and week as number \n",
    "#returns dataframe of scraped data\n",
    "def scrape_weekly_player_projections_SCOUT(week, year):\n",
    "    ###GET PROJECTIONS FROM SCOUT###\n",
    "    #SCOUT has separate tables for each position, so need to cycle through them\n",
    "    #but url can return whole list so don't need to go page by page\n",
    "    proj_ppr_scout = pd.DataFrame()\n",
    "    \n",
    "    positions = ['QB', 'RB', 'WR', 'TE', 'K', 'DEF']\n",
    "       \n",
    "    for position in positions:\n",
    "        #url just needs to change position and week\n",
    "        url = f\"https://fftoolbox.scoutfantasysports.com/football/rankings/?pos={position}&week={week}&noppr=false\"\n",
    "    \n",
    "        #response returns html\n",
    "        response = requests.get(url, verify=False) #need verify false otherwise requests won't work on this site\n",
    "\n",
    "        #extract the table data from the html response (call response.text) and get table with player data\n",
    "        proj_ppr_scout_pos = pd.read_html(response.text, #response.text gives the html of the page request\n",
    "                                       attrs={'class': 'responsive-table'}, #return only the table of this class, which has the player data\n",
    "                                       header=0 #header is the 0th row\n",
    "                                       )[0] #returns list of tables so get the table\n",
    "     \n",
    "        #add the table to the overall df\n",
    "        proj_ppr_scout = pd.concat([proj_ppr_scout, proj_ppr_scout_pos], \n",
    "                             ignore_index=True, \n",
    "                             sort=False)\n",
    "\n",
    "    #ads are included in table rows (eg 'googletag.defineSlot(\"/7103/SMG_FFToolBox/728x...')\n",
    "    #so need to find the index values of those rows and then drop them from the table\n",
    "    index_ads_rows = list(proj_ppr_scout[proj_ppr_scout['#'].str.contains('google')].index)\n",
    "    proj_ppr_scout.drop(index_ads_rows, axis='index', inplace=True)\n",
    "    \n",
    "    #add columns that give week/season\n",
    "    proj_ppr_scout['WEEK'] = week\n",
    "    proj_ppr_scout['SEASON'] = year\n",
    "    \n",
    "    return proj_ppr_scout   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "###FORMAT/EXTRACT ACTUAL PLAYER PPR DATA###\n",
    "#(you could make this more complex if want to extract some of the subdata)\n",
    "\n",
    "def format_extract_PPR_player_points_SCOUT(df_scraped_ppr_scout):\n",
    "    #rename columns\n",
    "    df_scraped_ppr_scout.rename(columns={'Projected Pts.':'FPTS_PPR_SCOUT',\n",
    "                                         'Player':'PLAYER',\n",
    "                                         'Pos':'POS',\n",
    "                                         'Team':'TEAM'},\n",
    "                                inplace=True) \n",
    "                              \n",
    "\n",
    "    #some players (very few - mostly kickers) seem to have name as last, first instead of written out\n",
    "    #also rename defenses from City/State to Mascot\n",
    "    #create dictionary for geographical location to mascot (use this for some Defense renaming) based on this website's naming\n",
    "    NFL_team_mascot = {'Arizona': 'Cardinals',\n",
    "                        'Atlanta': 'Falcons',\n",
    "                        'Baltimore': 'Ravens',\n",
    "                        'Buffalo': 'Bills',\n",
    "                        'Carolina': 'Panthers',\n",
    "                        'Chicago': 'Bears',\n",
    "                        'Cincinnati': 'Bengals',\n",
    "                        'Cleveland': 'Browns',\n",
    "                        'Dallas': 'Cowboys',\n",
    "                        'Denver': 'Broncos',\n",
    "                        'Detroit': 'Lions',\n",
    "                        'Green Bay': 'Packers',\n",
    "                        'Houston': 'Texans',\n",
    "                        'Indianapolis': 'Colts',\n",
    "                        'Jacksonville': 'Jaguars',\n",
    "                        'Kansas City': 'Chiefs',\n",
    "                        #'Los Angeles': 'Rams',\n",
    "                        'Miami': 'Dolphins',\n",
    "                        'Minnesota': 'Vikings',\n",
    "                        'New England': 'Patriots',\n",
    "                        'New Orleans': 'Saints',\n",
    "                        'New York Giants': 'Giants',\n",
    "                        'New York Jets': 'Jets',\n",
    "                        'Oakland': 'Raiders',\n",
    "                        'Philadelphia': 'Eagles',\n",
    "                        'Pittsburgh': 'Steelers',\n",
    "                        #'Los Angeles': 'Chargers',\n",
    "                        'Seattle': 'Seahawks',\n",
    "                        'San Francisco': '49ers',\n",
    "                        'Tampa Bay': 'Buccaneers',\n",
    "                        'Tennessee': 'Titans',\n",
    "                        'Washington': 'Redskins'}\n",
    "    #get Los Angelse defense data for assigning D's\n",
    "    LosAngeles_defense_ranks = [int(x) for x in df_scraped_ppr_scout['#'][df_scraped_ppr_scout.PLAYER == 'Los Angeles'].tolist()]\n",
    "    print(LosAngeles_defense_ranks)\n",
    "    #in this function the defense rename here is SUPER GLITCHY since there are two Defenses' names 'Los Angeles', for now this code assumes the higher pts Defense is LA Rams\n",
    "    def modify_player_name_scout(player, pos, rank):\n",
    "        #defense need to change from city to mascot\n",
    "        if pos == 'Def':\n",
    "            #if Los Angeles is geographic location, then use minimum rank to Rams (assuming they are better defense)\n",
    "            if player == 'Los Angeles' and int(rank) == min(LosAngeles_defense_ranks):\n",
    "                player_formatted = 'Rams'\n",
    "            elif player == 'Los Angeles' and int(rank) == max(LosAngeles_defense_ranks):\n",
    "                player_formatted = 'Chargers'\n",
    "            else:    \n",
    "                player_formatted = NFL_team_mascot.get(player)\n",
    "        else:\n",
    "            #if incoming string for players: 'Johnson, David' Change to: 'David Johnson' (this is rare - mostly for kickers on this site for som reason)\n",
    "            if ',' in player:\n",
    "                player = ' '.join(player.split(', ')[::-1])\n",
    "            #remove suffixes/periods for all players    \n",
    "            player_formatted = remove_suffixes_periods(player)\n",
    "        \n",
    "        #hard override of some player names that don't match to ESPN naming\n",
    "        if player_formatted == 'Juju Smith-Schuster': \n",
    "            player_formatted = 'JuJu Smith-Schuster'\n",
    "        elif player_formatted == 'Steven Hauschka':\n",
    "            player_formatted = 'Stephen Hauschka'\n",
    "            \n",
    "        return player_formatted\n",
    "               \n",
    "    \n",
    "    df_scraped_ppr_scout['PLAYER'] = df_scraped_ppr_scout.apply(\n",
    "                                                    lambda row: modify_player_name_scout(row['PLAYER'], row['POS'], row['#']),\n",
    "                                                    axis='columns')\n",
    "\n",
    "    \n",
    "    #for this function only extract 'PLAYER', 'POS', 'TEAM', 'PTS', 'WEEK' (note Team is blank because webpage uses images for teams)\n",
    "    df_scraped_ppr_scout = df_scraped_ppr_scout[['PLAYER', 'POS', 'TEAM', 'FPTS_PPR_SCOUT', 'WEEK']].sort_values('FPTS_PPR_SCOUT', ascending=False)\n",
    "\n",
    "\n",
    "    return df_scraped_ppr_scout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\urllib3\\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\micha\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\urllib3\\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\micha\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\urllib3\\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\micha\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\urllib3\\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\micha\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\urllib3\\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\micha\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\urllib3\\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle saved to: pickle_archive/Week1_PPR_Projections_SCOUT_messy_scrape_2018-9-15-22-10.pkl\n",
      "[4, 9]\n",
      "Pickle saved to: pickle_archive/Week1_PPR_Projections_SCOUT_2018-9-15-22-10.pkl\n",
      "(388, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>POS</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>FPTS_PPR_SCOUT</th>\n",
       "      <th>WEEK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Alvin Kamara</td>\n",
       "      <td>RB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Todd Gurley</td>\n",
       "      <td>RB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Leonard Fournette</td>\n",
       "      <td>RB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>QB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>David Johnson</td>\n",
       "      <td>RB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               PLAYER POS  TEAM  FPTS_PPR_SCOUT  WEEK\n",
       "34       Alvin Kamara  RB   NaN            34.0     1\n",
       "35        Todd Gurley  RB   NaN            28.5     1\n",
       "36  Leonard Fournette  RB   NaN            27.2     1\n",
       "0       Aaron Rodgers  QB   NaN            27.1     1\n",
       "37      David Johnson  RB   NaN            27.0     1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WEEK 1 PROJECTIONS\n",
    "#CALL SCRAPE AND FORMATTING OF SCOUT WEEKLY PROJECTIONS - AND SAVE TO PICKLES FOR LATER USE\n",
    "\n",
    "#scrape data and save the messy full dataframe\n",
    "df_wk1_ppr_proj_scout_scrape = scrape_weekly_player_projections_SCOUT(1, 2018)\n",
    "save_to_pickle(df_wk1_ppr_proj_scout_scrape, 'pickle_archive', 'Week1_PPR_Projections_SCOUT_messy_scrape')\n",
    "\n",
    "#format data to extract just player pts/playr/pos/team and save the data\n",
    "df_wk1_ppr_proj_scout = format_extract_PPR_player_points_SCOUT(df_wk1_ppr_proj_scout_scrape)\n",
    "save_to_pickle(df_wk1_ppr_proj_scout, 'pickle_archive', 'Week1_PPR_Projections_SCOUT')\n",
    "print(df_wk1_ppr_proj_scout.shape)\n",
    "df_wk1_ppr_proj_scout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\urllib3\\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\micha\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\urllib3\\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\micha\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\urllib3\\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\micha\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\urllib3\\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\micha\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\urllib3\\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\micha\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\urllib3\\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle saved to: pickle_archive/Week2_PPR_Projections_SCOUT_messy_scrape_2018-9-15-22-10.pkl\n",
      "[4, 5]\n",
      "Pickle saved to: pickle_archive/Week2_PPR_Projections_SCOUT_2018-9-15-22-10.pkl\n",
      "(377, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>POS</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>FPTS_PPR_SCOUT</th>\n",
       "      <th>WEEK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Alvin Kamara</td>\n",
       "      <td>RB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Todd Gurley</td>\n",
       "      <td>RB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jared Goff</td>\n",
       "      <td>QB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drew Brees</td>\n",
       "      <td>QB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ben Roethlisberger</td>\n",
       "      <td>QB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                PLAYER POS  TEAM  FPTS_PPR_SCOUT  WEEK\n",
       "35        Alvin Kamara  RB   NaN            32.0     2\n",
       "36         Todd Gurley  RB   NaN            31.9     2\n",
       "0           Jared Goff  QB   NaN            28.4     2\n",
       "1           Drew Brees  QB   NaN            27.6     2\n",
       "2   Ben Roethlisberger  QB   NaN            27.4     2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WEEK 2 PROJECTIONS\n",
    "#CALL SCRAPE AND FORMATTING OF SCOUT WEEKLY PROJECTIONS - AND SAVE TO PICKLES FOR LATER USE\n",
    "\n",
    "#scrape data and save the messy full dataframe\n",
    "df_wk2_ppr_proj_scout_scrape = scrape_weekly_player_projections_SCOUT(2, 2018)\n",
    "save_to_pickle(df_wk2_ppr_proj_scout_scrape, 'pickle_archive', 'Week2_PPR_Projections_SCOUT_messy_scrape')\n",
    "\n",
    "#format data to extract just player pts/playr/pos/team and save the data\n",
    "df_wk2_ppr_proj_scout = format_extract_PPR_player_points_SCOUT(df_wk2_ppr_proj_scout_scrape)\n",
    "save_to_pickle(df_wk2_ppr_proj_scout, 'pickle_archive', 'Week2_PPR_Projections_SCOUT')\n",
    "print(df_wk2_ppr_proj_scout.shape)\n",
    "df_wk2_ppr_proj_scout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get FanDuel Player Salaries for Week \n",
    "#### just import the Thurs-Mon game salaries (they differ for each game type, and note they don't include Kickers in the Thurs-Mon)\n",
    "Go to a FanDuel Thurs-Mon competition and Download a csv of players, which we then upload and format in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "###FORMAT/EXTRACT FANDUEL SALARY INFO###\n",
    "\n",
    "def format_extract_FanDuel(df_fanduel_csv, week, year):\n",
    "    #rename columns\n",
    "    df_fanduel_csv.rename(columns={'Position':'POS',\n",
    "                                    'Nickname':'PLAYER',\n",
    "                                    'Team':'TEAM',\n",
    "                                    'Salary':'SALARY_FANDUEL'},\n",
    "                            inplace=True) \n",
    "    \n",
    "    #add week/season columns\n",
    "    df_fanduel_csv['WEEK'] = week\n",
    "    df_fanduel_csv['SEASON'] = year\n",
    "\n",
    "    #fix names\n",
    "    def modify_player_name_fanduel(player, pos):\n",
    "        #defense comes in as 'Dallas Cowboys' or 'Tampa Bay Buccaneers' need to split and take last word, which is the team mascot, just 'Cowboys' or 'Buccaneers'\n",
    "        if pos == 'D':\n",
    "            player_formatted = player.split()[-1]\n",
    "            \n",
    "        else:\n",
    "            #need to remove suffixes, etc. \n",
    "            player_formatted = remove_suffixes_periods(player)\n",
    "        \n",
    "        #hard override of some player names that don't match to ESPN naming\n",
    "        if player_formatted == 'Josh Bellamy':\n",
    "            player_formatted = 'Joshua Bellamy'\n",
    "            \n",
    "        return player_formatted\n",
    "               \n",
    "    \n",
    "    df_fanduel_csv['PLAYER'] = df_fanduel_csv.apply(\n",
    "                                        lambda row: modify_player_name_fanduel(row['PLAYER'], row['POS']),\n",
    "                                        axis='columns')\n",
    "\n",
    "    \n",
    "    #for this function only extract 'PLAYER', 'POS', 'TEAM', 'SALARY', 'WEEK' (note Team is blank because webpage uses images for teams)\n",
    "    df_fanduel_csv = df_fanduel_csv[['PLAYER', 'POS', 'TEAM', 'SALARY_FANDUEL', 'WEEK']].sort_values('SALARY_FANDUEL', ascending=False)\n",
    "\n",
    "\n",
    "    return df_fanduel_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle saved to: pickle_archive/Week2_Salary_FanDuel_2018-9-15-22-40.pkl\n",
      "(669, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>POS</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>SALARY_FANDUEL</th>\n",
       "      <th>WEEK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alvin Kamara</td>\n",
       "      <td>RB</td>\n",
       "      <td>NO</td>\n",
       "      <td>9000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Todd Gurley</td>\n",
       "      <td>RB</td>\n",
       "      <td>LAR</td>\n",
       "      <td>8900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Antonio Brown</td>\n",
       "      <td>WR</td>\n",
       "      <td>PIT</td>\n",
       "      <td>8900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drew Brees</td>\n",
       "      <td>QB</td>\n",
       "      <td>NO</td>\n",
       "      <td>8800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michael Thomas</td>\n",
       "      <td>WR</td>\n",
       "      <td>NO</td>\n",
       "      <td>8800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           PLAYER POS TEAM  SALARY_FANDUEL  WEEK\n",
       "0    Alvin Kamara  RB   NO            9000     1\n",
       "2     Todd Gurley  RB  LAR            8900     1\n",
       "1   Antonio Brown  WR  PIT            8900     1\n",
       "3      Drew Brees  QB   NO            8800     1\n",
       "4  Michael Thomas  WR   NO            8800     1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WEEK 2 FANDUEL SALARIES\n",
    "\n",
    "#import csv from FanDuel\n",
    "df_wk2_fanduel_csv = pd.read_csv('fanduel_salaries/Week2-FanDuel-NFL-2018-09-13-28179-players-list.csv')\n",
    "\n",
    "#format data to extract just player salary/player/pos/team and save the data\n",
    "df_wk2_fanduel = format_extract_FanDuel(df_wk2_fanduel_csv, 1, 2018)\n",
    "save_to_pickle(df_wk2_fanduel, 'pickle_archive', 'Week2_Salary_FanDuel')\n",
    "print(df_wk2_fanduel.shape)\n",
    "df_wk2_fanduel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### !!!FFtoday apparently doesn't do weekly projections for Defenses, so don't use it for now (can check back in future and see if updated)!!!\n",
    "\n",
    "#### Get FFtoday Player Fantasy Points Projections for Week \n",
    "Get from FFtoday's Projections Table\n",
    "\n",
    "http://www.fftoday.com/rankings/playerwkproj.php?Season=2018&GameWeek=2&PosID=10&LeagueID=107644\n",
    "- Season = year\n",
    "- GameWeek = week\n",
    "- PosID = the id for each position 'QB':10, 'RB':20, 'WR':30, 'TE':40, 'K':80, 'DEF':99\n",
    "- LeagueID = the scoring type, 107644 gives FFToday PPR scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##SCRAPE FFtoday PROJECTIONS TABLE FOR PROJECTED FANTASY PPR POINTS##\n",
    "\n",
    "# #input needs to be year as four digit number and week as number \n",
    "# #returns dataframe of scraped data\n",
    "# def scrape_weekly_player_projections_FFtoday(week, year):\n",
    "#     #instantiate selenium driver\n",
    "#     driver = instantiate_selenium_driver()\n",
    "    \n",
    "#     #initialize dataframe for all data\n",
    "#     proj_ppr_fft = pd.DataFrame()\n",
    "    \n",
    "#     #url that returns info has different code for each position and also takes year variable\n",
    "#     position_ids = {'QB':10, 'RB':20, 'WR':30, 'TE':40, 'K':80, 'DEF':99}\n",
    "\n",
    "\n",
    "#     #cycle through each position webpage to create comprehensive dataframe\n",
    "#     for pos, pos_id in position_ids.items():\n",
    "#         url_start_pos = f\"http://www.fftoday.com/rankings/playerwkproj.php?Season={year}&GameWeek={week}&PosID={pos_id}&LeagueID=107644\"\n",
    "#         driver.get(url_start_pos)\n",
    "        \n",
    "#         #each page only gets 50 results, so cycle through next button until next button no longer exists\n",
    "#         while True:\n",
    "#             #read in table - no classes for tables so just need to find the right table in the list of tables from the page - 5th index\n",
    "#             proj_ppr_fft_table_page = pd.read_html(driver.page_source, header=[1])[5]\n",
    "            \n",
    "#             proj_ppr_fft_table_page['POS'] = pos\n",
    "            \n",
    "          \n",
    "#             #need to rename columns for different positions before concat because of differing column conventions\n",
    "#             if pos == 'QB':\n",
    "#                 proj_ppr_fft_table_page.rename(columns={'Player  Sort First: Last:':'PLAYER',\n",
    "#                                                   'Comp':'PASS_COMP', 'Att': 'PASS_ATT', 'Yard':'PASS_YD',\n",
    "#                                                   'TD':'PASS_TD', 'INT':'PASS_INT',\n",
    "#                                                   'Att.1':'RUSH_ATT', 'Yard.1':'RUSH_YD', 'TD.1':'RUSH_TD'},\n",
    "#                                          inplace=True)\n",
    "#             elif pos == 'RB':\n",
    "#                 proj_ppr_fft_table_page.rename(columns={'Player  Sort First: Last:':'PLAYER',\n",
    "#                                                   'Att': 'RUSH_ATT', 'Yard':'RUSH_YD', 'TD':'RUSH_TD',\n",
    "#                                                    'Rec':'RECV_RECPT', 'Yard.1':'RECV_YD', 'TD.1':'RECV_TD'},\n",
    "#                                          inplace=True)\n",
    "                \n",
    "#             elif pos == 'WR':\n",
    "#                 proj_ppr_fft_table_page.rename(columns={'Player  Sort First: Last:':'PLAYER',\n",
    "#                                                   'Rec':'RECV_RECPT', 'Yard':'RECV_YD', 'TD':'RECV_TD',\n",
    "#                                                   'Att':'RUSH_ATT', 'Yard.1':'RUSH_YD', 'TD.1':'RUSH_TD'},\n",
    "#                                          inplace=True)\n",
    "            \n",
    "#             elif pos == 'TE':\n",
    "#                 proj_ppr_fft_table_page.rename(columns={'Player  Sort First: Last:':'PLAYER',\n",
    "#                                                   'Rec':'RECV_RECPT', 'Yard':'RECV_YD', 'TD':'RECV_TD'},\n",
    "#                                          inplace=True)\n",
    "                \n",
    "#             elif pos == 'K':\n",
    "#                 proj_ppr_fft_table_page.rename(columns={'Player  Sort First: Last:':'PLAYER',\n",
    "#                                                   'FGM':'KICK_FG', 'FGA':'KICK_FGAtt', 'FG%':'KICK_FG%',\n",
    "#                                                   'EPM':'KICK_XP', 'EPA':'KICK_XPAtt'},\n",
    "#                                          inplace=True)\n",
    "            \n",
    "#             elif pos == 'DEF':\n",
    "#                 proj_ppr_fft_table_page['PLAYER'] = proj_ppr_fft_table_page['Team'] #+ ' D/ST' #add player name with team name plus D/ST tag\n",
    "#                 proj_ppr_fft_table_page.rename(columns={'Sack':'D/ST_Sack', 'FR':'D/ST_FR', 'DefTD':'D/ST_TD', 'INT':'D/ST_INT',\n",
    "#                                                    'PA':'D/ST_PtsAll', 'PaYd/G':'D/ST_PaYd/G', 'RuYd/G':'D/ST_RuYd/G',\n",
    "#                                                    'Safety':'D/ST_Sty', 'KickTD':'D/ST_RET_TD'},\n",
    "#                                          inplace=True)\n",
    "            \n",
    "            \n",
    "#             #add the position/page data to overall df\n",
    "#             proj_ppr_fft = pd.concat([proj_ppr_fft, proj_ppr_fft_table_page],\n",
    "#                                     ignore_index=True,\n",
    "#                                     sort=False)\n",
    "            \n",
    "            \n",
    "#             #click to next page to get next 50 results, but check that next button exists\n",
    "#             try:\n",
    "#                 next_button = driver.find_element_by_link_text(\"Next Page\")\n",
    "#                 next_button.click()\n",
    "#             except EC.NoSuchElementException:\n",
    "#                 break\n",
    "    \n",
    "    \n",
    "#     driver.quit()\n",
    "    \n",
    "#     #add columns that give week/season\n",
    "#     proj_ppr_fft['WEEK'] = week\n",
    "#     proj_ppr_fft['SEASON'] = year\n",
    "    \n",
    "    \n",
    "#     return proj_ppr_fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###FORMAT/EXTRACT ACTUAL PLAYER PPR DATA###\n",
    "# #(you could make this more complex if want to extract some of the subdata)\n",
    "\n",
    "# def format_extract_PPR_player_points_FFtoday(df_scraped_ppr_fft):\n",
    "# # #optional data formatting for additional info\n",
    "# #     #calculate completion percentage\n",
    "# #     df_scraped_ppr_fft['PASS_COMP_PCT'] = df_scraped_ppr_fft.PASS_COMP/df_scraped_ppr_fft.PASS_ATT\n",
    "\n",
    "\n",
    "# #     #calculate total PaYd and RuYd for season\n",
    "# #     df_scraped_ppr_fft['D/ST_PaYdA'] = df_scraped_ppr_fft['D/ST_PaYd/G'] * 16\n",
    "# #     df_scraped_ppr_fft['D/ST_RuYdA'] = df_scraped_ppr_fft['D/ST_RuYd/G'] * 16\n",
    "# #     df_scraped_ppr_fft['D/ST_ToYd/G'] = df_scraped_ppr_fft['D/ST_PaYd/G'] + df_scraped_ppr_fft['D/ST_RuYd/G']\n",
    "# #     df_scraped_ppr_fft['D/ST_ToYdA'] = df_scraped_ppr_fft['D/ST_ToYd/G'] * 16\n",
    "\n",
    "\n",
    "#     #rename some of outstanding columns to match other dfs\n",
    "#     df_scraped_ppr_fft.rename(columns={'Team':'TEAM', 'FPts':'FPTS_PPR_FFTODAY'},\n",
    "#                              inplace=True)\n",
    "\n",
    "#     #remove any possible name suffixes to merge with other data better\n",
    "#     df_scraped_ppr_fft['PLAYER'] = df_scraped_ppr_fft['PLAYER'].map(remove_suffixes_periods)\n",
    "    \n",
    "    \n",
    "#     #for this function only extract 'PLAYER', 'POS', 'TEAM', 'PTS'\n",
    "#     df_scraped_ppr_fft = df_scraped_ppr_fft[['PLAYER', 'POS', 'TEAM', 'FPTS_PPR_FFTODAY', 'WEEK']].sort_values('FPTS_PPR_FFTODAY', ascending=False)\n",
    "\n",
    "#     return df_scraped_ppr_fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Database Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual_ppr_df = pd.read_pickle('pickle_archive/Week1_Player_Actual_PPR_2018-9-13-6-41.pkl')\n",
    "# espn_final_df = pd.read_pickle('pickle_archive/Week1_PPR_Projections_ESPN_2018-9-13-6-46.pkl')\n",
    "# cbs_final_df = pd.read_pickle('pickle_archive/Week1_PPR_Projections_CBS_2018-9-13-17-45.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cbs_final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sqlalchemy import create_engine\n",
    "\n",
    "# disk_engine = create_engine('sqlite:///my_lite_store.db')\n",
    "# actual_ppr_df.to_sql('actual_ppr', disk_engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# espn_final_df.to_sql('espn_final_df', disk_engine, if_exists='append')\n",
    "# cbs_final_df.to_sql('cbs_final_df', disk_engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
